train_path: "" # help="str The path to the training set"
dev_path: "" # help="str The path to the development set"
test_path: "" # help="str The path to the test set"
out_dir_path: "" # help="str The path to the output directory"
prompt_id: "" # help="int Promp ID for ASAP dataset. '0' means all prompts."
model_type: "regp" # help="str Model type (reg|regp|breg|bregp) (default=regp)"
recurrent_unit: "lstm" # help="str Recurrent unit type (lstm|gru|simple) (default=lstm)"
algorithm: 'rmsprop' # help="str Optimization algorithm (rmsprop|sgd|adagrad|adadelta|adam|adamax) (default=rmsprop)"
loss: 'mse' # help="Loss function (mse|mae) (default=mse)"
emb_dim: 50 # help="Embeddings dimension (default=50)"
cnn_dim: 0 # help="CNN output dimension. '0' means no CNN layer (default=0)"
cnn_window_size: 3 # help="int CNN window size. (default=3)"
rnn_dim: 300 # help="RNN dimension. '0' means no RNN layer (default=300)"
batch_size: 32 # help="Batch size (default=32)"
vocab_size: 4000 # help="Vocab size (default=4000)"
aggregation: 'mot' # help="The aggregation method for regp and bregp types (mot|attsum|attmean) (default=mot)"
dropout_prob: 0.5 # help="The dropout probability. To disable, give a negative number (default=0.5)"
vocab_path: "" # help="str (Optional) The path to the existing vocab file (*.pkl)"
skip_init_bias: true # help="Skip initialization of the last layer bias"
emb_path: "" # help="str The path to the word embeddings file (Word2Vec format)"
epochs: 50 # help="Number of epochs (default=50)"
maxlen: 0 # help="Maximum allowed number of words during training. '0' means no limit (default=0)"
seed: 1234 # help="Random seed (default=1234)"